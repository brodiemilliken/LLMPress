# Optimal configuration for GPT2 model
compression:
  window_size: 128     # Optimal sliding context window for GPT2
  min_chunk_size: 200  # Minimum chunk size in bytes
  max_chunk_size: 500  # Maximum chunk size in bytes

general:
  model_name: gpt2     # Model identifier
  log_level: normal    # Logging level (quiet, normal, verbose, debug)